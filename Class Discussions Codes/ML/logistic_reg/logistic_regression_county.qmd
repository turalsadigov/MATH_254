---
title: Logistic Regression - County data
author: Tural Sadigov
format: 
    html:
      theme: 
        dark: darkly
        light: united
      fig-width: 8
      fig-height: 6
title-block-banner: true
execute:
  echo: fenced
  warning: false
  message: false
  tidy: true
  eval: true
  output: true
  error: false
  freeze: true
  out.width: "100%"
  cache: true
code-fold: show
bibliography: references.bib
---

## libraries and data

We use tidyverse (@tidyverse) for data wrangling, tidymodels (@tidymodels) for modeling and stats2data (@stats2data) for the data.

```{r}
library(tidyverse)
library(tidymodels)
library(stats2data)
# one <- 'https://raw.githubusercontent.com/'
# two <- 'turalsadigov/'
# three <- 'MATH_254/main/data/'
# four <- 'county.csv'
# url <- str_c(one, two, three, four)
# county <- read_csv(url)
```

## county wrangling and EDA

```{r}
county %>% 
  count(metro) %>% 
  drop_na() %>% 
  mutate(percent = n/sum(n))

county %>% 
  select(metro, pop2017) %>% 
  drop_na() %>% 
  mutate(pop_dummy = if_else(pop2017>median(pop2017), 
                             'above', 'below')) %>% 
  count(pop_dummy, metro) %>% 
  group_by(pop_dummy) %>% 
  mutate(percent = n/sum(n))

county %>% 
  select(metro, median_hh_income) %>% 
  drop_na() %>% 
  mutate(income_dummy = if_else(median_hh_income > median(median_hh_income), 
                                'above', 'below')) %>% 
  count(income_dummy, metro) %>% 
  group_by(income_dummy) %>% 
  mutate(percent = n/sum(n))


county %>% 
  select(metro, median_hh_income, pop2017) %>% 
  drop_na() %>% 
  mutate(income_dummy = if_else(median_hh_income > median(median_hh_income), 
                                'above', 'below'),
         pop_dummy = if_else(pop2017>median(pop2017), 
                             'above', 'below')) %>% 
  count(pop_dummy, income_dummy, metro) %>% 
  group_by(pop_dummy, income_dummy) %>% 
  mutate(percent = n/sum(n))
```

```{r}
skimr::skim(county)

df <- stats2data::county %>% 
  select(name, state, pop2017, median_hh_income, metro) %>% 
  unite('name/state', name:state, sep = '/') %>% 
  mutate(metro = factor(metro)) %>% 
  drop_na()

skimr::skim(df)

df %>% 
  count(metro) %>% 
  mutate(n/sum(n))

p1 <- df %>% 
  ggplot(aes(x = metro, y = log(pop2017), fill = metro)) +
  geom_boxplot() 

p2 <- df %>% 
  ggplot(aes(x = metro, y = log(median_hh_income), fill = metro)) +
  geom_boxplot() 

library(patchwork)
p1+p2



p11 <- df %>% 
  ggplot(aes(x = metro, y = log(pop2017), fill = metro)) +
  geom_violin()

p22 <- df %>% 
  ggplot(aes(x = metro, y = log(median_hh_income), fill = metro)) +
  geom_violin()

library(patchwork)
p11+p22


df %>% 
  select(-`name/state`) %>% 
  GGally::ggpairs(aes(fill = metro))


p3 <- df %>% 
  mutate(metro_dummy = if_else(metro == 'yes', 1, 0)) %>% 
  ggplot(aes(x = pop2017, metro_dummy)) +
  geom_point() +
  geom_jitter(height = 0.1, alpha = 0.3)

p4 <- df %>% 
  mutate(metro_dummy = if_else(metro == 'yes', 1, 0)) %>% 
  ggplot(aes(x = log(pop2017), metro_dummy)) +
  geom_point() +
  geom_jitter(height = 0.1, alpha = 0.3)


p5 <- df %>% 
  mutate(metro_dummy = if_else(metro == 'yes', 1, 0)) %>% 
  ggplot(aes(x = median_hh_income, metro_dummy)) +
  geom_point() +
  geom_jitter(height = 0.1, alpha = 0.3)

p3 + p4 + p5
```

## data split

```{r}

df <- 
  df %>% 
  mutate(pop2017 = log(pop2017))
set.seed(2022)
df_split <- initial_split(data = df, 
                          prop = 0.80, 
                          strata = metro)
df_training <- training(df_split)
df_testing <- testing(df_split)

# 20 bootstrap samples
num_boot_samples <- 20
set.seed(2023)
df_boot_resamples <-  bootstraps(data = df_training, 
                                 times = num_boot_samples, 
                                 strata = metro)

df_boot_resamples
```

## create model specifications and recipes for modeling

```{r}
logistic_spec <- 
  logistic_reg() %>% 
  set_engine('glm') %>% 
  set_mode('classification')

rec_null <- recipe(metro ~ 1, data = df_training)
rec_1 <- recipe(metro ~ pop2017, data = df_training) 
rec_2 <- recipe(metro ~ median_hh_income, data = df_training)
rec_3 <- recipe(metro ~ pop2017 + median_hh_income, data = df_training)
rec_4 <- recipe(metro ~ pop2017 + median_hh_income, data = df_training) %>%
  step_interact(terms = ~ pop2017:median_hh_income) 

```

## modeling via PARALLEL PROGRAMMING

For parallel programming we use parallel (@parallel) and doParallel (@doParallel).

```{r}
# detect number of cores in your local machine
parallel::detectCores(logical = FALSE)

# call it all_cores
all_cores <- parallel::detectCores(logical = FALSE)

# start parallel programming
library(doParallel)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)

model_null <- 
  workflow() %>% 
  add_model(logistic_spec) %>% 
  add_recipe(rec_null) %>% 
  fit_resamples(df_boot_resamples)
  
model_1 <- 
  workflow() %>% 
  add_model(logistic_spec) %>% 
  add_recipe(rec_1) %>% 
  fit_resamples(df_boot_resamples)

model_2 <- 
  workflow() %>% 
  add_model(logistic_spec) %>% 
  add_recipe(rec_2) %>% 
  fit_resamples(df_boot_resamples)

model_3 <- 
  workflow() %>% 
  add_model(logistic_spec) %>% 
  add_recipe(rec_3) %>% 
  fit_resamples(df_boot_resamples)

model_4 <- 
  workflow() %>% 
  add_model(logistic_spec) %>% 
  add_recipe(rec_4) %>% 
  fit_resamples(df_boot_resamples)
```

## model comparison

```{r}
fitted_models <- list(model_null, model_1, model_2, model_3, model_4)
all_models <- tibble()
for(model in fitted_models){
  all_models <- all_models %>% 
    bind_rows(collect_metrics(model))
}
all_models %>% 
  filter(.metric == 'accuracy') %>% 
  mutate(model_name = c('Null', seq(1, 4))) %>% 
  arrange(desc(mean))
```

## CHOSEN ONE!

`model_3` is a simpler model with similar accuracy, so we choose the simpler model using the principle of parsimony (@parsimon2002).

Remember the famous quota attributed to Einstein**: "Models should be simple enough but not too simple"** ( or, "Everything should be made as simple as possible, but no simpler", @robinson2018).

```{r}
# chosen model
chosen_model <- 
  workflow() %>% 
  add_model(logistic_spec) %>% 
  add_recipe(rec_3) %>% 
  last_fit(df_split)
chosen_model

# create a demo model for sketching sigmoid
demo_model <- 
  workflow() %>% 
  add_model(logistic_spec) %>% 
  add_recipe(rec_1) %>% 
  last_fit(df_split)
```

## mathematical model

```{r}
extract_fit_engine(chosen_model) %>% 
  tidy()
```

$$
p = \frac{1}{1 + e^{-\left[-32.6 + 12.2 \log(x_1) + 0.0000717 x_2\right]}}, 
$$

where $x_1$ is the population of the county in 2017 , $x_2$ is the median household income in that county and $p$ is the conditional probability that a county has a metropolitan city in it given its population in 2017 and its median household income.

## model metrics and predictions

```{r}
collect_metrics(chosen_model) 
collect_predictions(chosen_model)
collect_predictions(chosen_model) %>% 
  conf_mat(truth = metro, estimate = .pred_class)
collect_predictions(chosen_model) %>% 
  accuracy(truth = metro, estimate = .pred_class)
collect_predictions(chosen_model) %>% 
  sensitivity(truth = metro, estimate = .pred_class)
collect_predictions(chosen_model) %>% 
  specificity(truth = metro, estimate = .pred_class)
collect_predictions(chosen_model) %>% 
  roc_curve(truth = metro, estimate = .pred_no) %>% 
  autoplot()


## demo model

extract_fit_engine(demo_model) %>% 
  tidy()
collect_metrics(demo_model) 
```

## sketch 2D curves

```{r}

# chosen model testing results

df_testing_results <- 
  collect_predictions(chosen_model) %>% 
  transmute(metro_dummy = if_else(metro == 'yes', 1, 0),
            .pred_yes) %>% 
  bind_cols(df_testing)


p6 <- df_testing_results %>% 
  ggplot(aes(log(pop2017))) +
  geom_point(aes(y = metro_dummy)) +
  geom_line(aes(y = .pred_yes))

p7 <- df_testing_results %>% 
  ggplot(aes(median_hh_income)) +
  geom_point(aes(y = metro_dummy)) +
  geom_line(aes(y = .pred_yes))

p6 + p7


## demo model results

demo_testing_results <- 
  collect_predictions(demo_model) %>% 
  transmute(metro_dummy = if_else(metro == 'yes', 1, 0),
            .pred_yes) %>% 
  bind_cols(df_testing)

demo_testing_results %>% 
  ggplot(aes(log(pop2017))) +
  geom_point(aes(y = metro_dummy)) +
  geom_line(aes(y = .pred_yes))
```

## scatterplot in 3D (point cloud)

`plotly` (@plotly) is a great library for 3D sketches both in R, Python and Java.

```{r}
library(plotly)

fig <- plot_ly(df_testing_results, 
               x = ~pop2017, 
               y = ~median_hh_income, 
               z = ~.pred_yes)
fig <- fig %>% add_markers()

fig

```

## scatterplot in 3D with labels colored

```{r}
fig2 <- plot_ly(df_testing_results, 
               x = ~pop2017, 
               y = ~median_hh_income, 
               z = ~.pred_yes, 
               color = ~metro, 
               colors = c('#BF382A', '#0C4B8E'))
fig2 <- fig2 %>% add_markers()

fig2
```

## decision boundary in 2D feature space

```{r}
b <- extract_fit_engine(chosen_model) %>% 
  tidy() %>% 
  pull(estimate)

slope <- - b[2]/b[3]
intercept <- -b[1]/b[3]
df_testing %>% 
  ggplot(aes(x = pop2017, y = median_hh_income)) +
  geom_point(aes(color = metro)) +
  geom_abline(slope = slope, intercept = intercept)
```

## save model for deployment

```{r}
save(chosen_model, file = 'county_logistic_model.Rdata')
```
